{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: Neural Networks with PyTorch\n",
    "---\n",
    "\n",
    "### Names: Keiran Berry\n",
    "### Course Level: Undergraduate\n",
    "---\n",
    "## Note: Due to the length of time required to train the ANN models, and there are 2-3 of them depending on the course level you are enrolled, please submit a PDF of your solution along with your .ipynb file\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "* In this project, we explore Artificial Neural Networks for dimensionality reduction and classification using PyTorch.\n",
    "\n",
    "<u>**Note:** The project will be graded by me running your notebook from top to bottom (choosing the \"run all\" option) - if it errors out at any point - this is where I stop grading and you'll lose ALL points after the error - Even if they are correct!</u>\n",
    "\n",
    "* <u>Moral of the story is, **Make sure your entire notebook executes from top to bottom and you're happy with the results BEFORE you submit to the drop box!**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "* The objective of this project is to use PyTorch to investigate ANN-based dimensionality reduction techniques and classifiers, then evaluate their performance on image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's grab the data and have a look at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem A (60pts)**\n",
    "\n",
    "We'll be looking at the Fashion MNIST data that we investigated in project 5, so go ahead and grab your project 5 code to read in the data.\n",
    "\n",
    "* Unlike project 5, we do NOT need to normalize our data between [-1,1], instead, we want our data to be normalized to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\101080740\\.cache\\kagglehub\\datasets\\zalando-research\\fashionmnist\\versions\\4\n"
     ]
    }
   ],
   "source": [
    "# imports, parameters, data, etc.\n",
    "# Fashion MNIST #\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub # need to install this: pip install kagglehub\n",
    "# !pip install kagglehub -U # update when needed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define Hyperparameters (can do this later if preferred)\n",
    "batch_size = 100 # Number of images we use before updating the gradients\n",
    "learning_rate = 0.001 # Learning rate for gradient updates\n",
    "epochs = 10 # Number of times to run through the entire training loop and all batches\n",
    "latent_dim = 64  # Dimension of the latent space\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "\n",
    "# The data is stored in a path on your hard drive in .csv files #\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Get the data from the .csv files #\n",
    "data_train = pd.read_csv(path + \"/fashion-mnist_train.csv\")\n",
    "data_test = pd.read_csv(path + \"/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 (10pts). Separate out the data between training and testing for both labels and data\n",
    "\n",
    "* Normalize between [0,1], convert to a torch tensor, and set up your dataloaders (one for training and one for testing)\n",
    "* **Recall:** We need our data to be of type torch tensor for using the pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m testX \u001b[38;5;241m=\u001b[39m testX \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# We don't need the labels to be tensors (yet) since we don't need them for an autoencoder (it's unsupervised)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m trainXTensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(trainX, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     18\u001b[0m testXTensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(testX, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# set up the dataloaders #\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Grab the training data and testing data and store for model development #\n",
    "# same code as Project 5\n",
    "trainX = data_train.iloc[:, 1:]  # first column is labels so we want the rest\n",
    "trainY = data_train.iloc[:, 0]   # now we want the labels\n",
    "\n",
    "testX = data_test.iloc[:, 1:] # rest are data\n",
    "testY = data_test.iloc[:, 0]  # first contains labels\n",
    "\n",
    "# Normalize the digits to [0,1] for better scaling and convert to torch tensors for processing #\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "\n",
    "# We don't need the labels to be tensors (yet) since we don't need them for an autoencoder (it's unsupervised)\n",
    "trainXTensor = torch.tensor(trainX.values, dtype = torch.float32)\n",
    "testXTensor = torch.tensor(testX.values, dtype = torch.float32)\n",
    "\n",
    "# set up the dataloaders #\n",
    "trainData = TensorDataset(trainXTensor)\n",
    "testData = TensorDataset(testXTensor)\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, shuffle = True)\n",
    "testLoader = DataLoader(testData, batch_size = 64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 (20pts). Define an Autoencoder Model\n",
    "\n",
    "* You can use the nn.Sequential module to define both the encoder and decoder.  \n",
    "* Use the following for dimensions:\n",
    "    - Encoder (single hidden layer):\n",
    "        + input_dim = 28*28 (size of image vector)\n",
    "        + hidden_dim = 256 (number of hidden neurons)\n",
    "        + latent_dim = 64 (dimension of the latent space)\n",
    "        + Note: the only dimension that is \"fixed\" is the input dimension (dictated by the number of features)\n",
    "            - Similar to PCA, the latent dimension controls how \"much\" information is kept\n",
    "        + Use linear activation for the hidden layer and ReLU for the latent output\n",
    "    - Decoder (single hidden layer):\n",
    "        + input_dim = latent_dim\n",
    "        + hidden_dim = 256 (number of hidden neurons)\n",
    "        + output_dim = 28*28 (same size as the image vectors)\n",
    "        + Note: the only dimension that is \"free\" is the hidden dimension (the others are dictated by the encoder and number of features)\n",
    "            - Output has to be the same as the input because we're \"comparing\" the reconstruction of each image as the loss\n",
    "        + Use ReLU activation for the hidden layer and Sigmoid for the decoder output (pixel range is [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder Model\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 256\n",
    "latent_dim = 64\n",
    "\n",
    "# defining autoencoder based on specifications\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),                        \n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),                        \n",
    "            nn.Linear(hidden_dim, input_dim),  \n",
    "            nn.Sigmoid()                   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 (10pts). Train the model\n",
    "\n",
    "* Use MSELoss, and the Adam optimizer.  The learning rate, epochs, batch size, etc. are all defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function (can also just wrap this into the training loop)\n",
    "# will be wrapping it into the training loop\n",
    "\n",
    "# Initialize Model, Loss, and Optimizer\n",
    "autoencoder = Autoencoder(input_dim, latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to Train the Autoencoder\n",
    "def trainAutoencoder(model, loader, criterion, optimizer, epochs):\n",
    "    model.train(True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        runningLoss = 0.0\n",
    "        for data in loader:\n",
    "            inputs = data[0].to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            #inputs = inputs.view(inputs.size(0), -1) # convert the images into a 1d vector\n",
    "            \n",
    "            optimizer.zero_grad() # gradients accumulate and we dont want that\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item()\n",
    "\n",
    "        # printing information for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {runningLoss/len(loader):.4f}\")\n",
    "    model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (e.g., write the Training Loop)\n",
    "trainAutoencoder(autoencoder, trainLoader, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 (10pts). Test your model for reconstruction of a few sample images\n",
    "\n",
    "* Create a 2 x 10 plot that shows one sample from each class with the top row containing the original images and the bottom row containing the reconstruction of these images\n",
    "    - e.g., grab one image from each class and plot it, then, run each image through your autoencoder to get the reconstructed version, and plot it to compare how \"well\" your autoencoder reconstructs the image\n",
    "\n",
    "* Your plot should look something like the image below:\n",
    "\n",
    "<img src=\"Figures/Recon.png\" alt=\"Autoencoder Reconstruction\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Autoencoder (write a quick function to grab the original images from the torch tensor, run them through the model, and generate the reconstructed images)\n",
    "# Your function should return both the original images you used, and their reconstruction\n",
    "def testAutoencoder(model, loader, numClasses = 10):\n",
    "    model.eval()\n",
    "    \n",
    "    classesSeen = set()\n",
    "    originalImages = []\n",
    "    reconstructedImages = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputsFlat = inputs.view(inputs.size(0), -1)\n",
    "            outputs = model(inputsFlat)\n",
    "            \n",
    "            for i in range(inputs.size(0)):\n",
    "                label = labels[i].item()\n",
    "                \n",
    "                if label not in classesSeen:\n",
    "                    originalImages.append(inputs[i].view(28, 28)) \n",
    "                    reconstructedImages.append(outputs[i].view(28, 28))\n",
    "                    \n",
    "                    classesSeen.add(label)\n",
    "                    \n",
    "                    if len(classesSeen) >= numClasses:\n",
    "                        break \n",
    "            if len(classesSeen) >= numClasses:\n",
    "                break\n",
    "    \n",
    "    return originalImages, reconstructedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Original and Reconstructed Images (use your function to crate the subplot, etc.)\n",
    "# Recall, your images are vectorized (785 dimensional) so you need to reshape them to visualize\n",
    "# You might consider looking at the .view() method in torch - works similar to the .reshape method in numpy\n",
    "\n",
    "# need the labels now \n",
    "testYTensor = torch.tensor(testY.values, dtype = torch.long)\n",
    "testData = TensorDataset(testXTensor, testYTensor)\n",
    "testLoader = DataLoader(testData, batch_size = 64, shuffle = False)\n",
    "\n",
    "originalImages, reconstructedImages = testAutoencoder(autoencoder, testLoader)\n",
    "\n",
    "fig, axes = plt.subplots(2, len(originalImages), figsize=(15, 5))\n",
    "    \n",
    "for i in range(len(originalImages)):\n",
    "    # top row\n",
    "    axes[0, i].imshow(originalImages[i].squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # bottom row\n",
    "    axes[1, i].imshow(reconstructedImages[i].squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "plt.suptitle('Original Images (Top) vs Reconstructed Images (Bottom)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 (10pts). Using the reduced dimensional data, build a shallow classifier (either logistic regression, tree, svc, etc.) on the reduced dimensional data and evaluate the classification performance (classification report and a confusion matrix)\n",
    "\n",
    "* Note that if we just use the encoder, we can effectively reduce the dimensionality of our data from 784 dimensions to the dimension of the latent space (64 in this case)\n",
    "    - This is \"similar\" to PCA, however, recall PCA assumes a linear model, here we've introduced some nonlinear activation so we're effectively doing nonlinear dimensionality reduction\n",
    "    - Note that the size of the latentspace dimension will have an effect on classification accuracy\n",
    "        + Recall that for PCA we needed around 80 components to capture approx. 85% of the variance\n",
    "\n",
    "#### **Important Note:** Your data (both input and output will be a torch tensor - numpy and matplot lib have no clue how to deal with that)\n",
    "* You need to detach your data from the torch graph, then convert from a tensor to a numpy array\n",
    "    - this is done via: my_numpy_data = my_tensor_data.detach().numpy() as a example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the training data onto the latent space, then\n",
    "# Convert the latent data from a torch tensor to a numpy array to build the sklearn classifier\n",
    "# Note: you must first detach the data from the torch tensor network (e.g., my_torch_data.detach().numpy() returns the numpy equivalent)\n",
    "\n",
    "autoEncoder.eval()\n",
    "latentData = []\n",
    "labels = []\n",
    "trainYTensor = torch.tensor(trainY.values, dtype = torch.long)\n",
    "trainData = TensorDataset(trainXTensor, trainYTensor)\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, shuffle = True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in trainLoader:\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        encoded = autoEncoder.encoder(inputs)\n",
    "        \n",
    "        latentData.append(encoded.detach().numpy())  # detatching as told in example\n",
    "        labels.append(targets.numpy())\n",
    "\n",
    "latentData = np.vstack(latentData)\n",
    "labels = np.hstack(labels) \n",
    "\n",
    "# training data should now be projected onto latent space\n",
    "# did labels as well just to be safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the shallow classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression.fit(latentData, labels)\n",
    "\n",
    "# need to do the same as before for the test set\n",
    "autoEncoder.eval()\n",
    "latentTest = []\n",
    "testLabels = []\n",
    "\n",
    "# already have the test loader from before\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in testLoader:\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        encoded = autoEncoder.encoder(inputs)\n",
    "        \n",
    "        latentTest.append(encoded.detach().numpy())  # detatching as told in example\n",
    "        labels.append(targets.numpy())\n",
    "\n",
    "latentTest = np.vstack(latentTest)\n",
    "testLabels = np.hstack(testLabels) \n",
    "\n",
    "testPredictions = logisticRegression.predict(latentTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the predicition accuracy \n",
    "# Get entire report of results #\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix from the predictions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(testLabels, testPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem B (40pts)**\n",
    "\n",
    "1 (20pts). Let's repeat the above experience but instead of doing any dimensionality reduction, we just use the MLP directly to do the classification, first step, build the MLP model\n",
    "\n",
    "* Although we can't \"prefectly\" match the autoencoder network topology, let's try to stay somewhat close for an apples to apples comparison:\n",
    "* **Hyperparameters**\n",
    "    - Three hidden layers: input_dim -> 256 -> 128 -> 64 -> num_classes\n",
    "    - Same learning rate, epochs, etc.\n",
    "    - Activation: use ReLU for all hidden units, and softmax for the output unit\n",
    "    - There are several loss functions you can use:  I used the CrossEntropy loss and it seems to do a pretty good job\n",
    "    - Use the Adam optimizer since we have many nonlinearities over the three layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to modify our dataloader since we now need the labels (supervised learning)\n",
    "from torch.utils.data import TensorDataset # useful to join the data and labels for the dataloader\n",
    "\n",
    "# Now we need to convert the labels to torch tensors as well (supervised)\n",
    "\n",
    "\n",
    "# Use the TensorDataset method to create a supervised training dataset (join the data)\n",
    "\n",
    "\n",
    "# set up the dataloaders (only need the dataloader for the training set) #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP Model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function (can also just wrap this into the training loop)\n",
    "\n",
    "# Initialize Model, Loss, and Optimizer\n",
    "\n",
    "\n",
    "# Function to Train the Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (e.g., write the Training Loop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: the network will produce a vector of 10 probabilities, you'll want to convert that to a class label, e.g., [0,1,2,3,4...] to match your testing labels and do the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for all samples (print the classification report, etc)#\n",
    "\n",
    "\n",
    "# Need to convert your predictions from a probabalistic output to a class label - np.argmax can help here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem A and B Discussion (provide a detailed discussion of the differences and results from each problem above - to include which categories are difficult to classify for each method, etc):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSC 549 Students Only!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo problem B but using a convolutional neural network (i.e., don't vectorize the images)\n",
    "\n",
    "* You can play with the model arcitecture, hyperparameters, activation, strides, pooling, etc. \n",
    "* Then compare and contrast the three different variations of the model with regard to classification of the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
